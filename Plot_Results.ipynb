{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8c2874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1697040354642,
     "user": {
      "displayName": "Konstandinos AIWANSEDO",
      "userId": "13653603513975002306"
     },
     "user_tz": -120
    },
    "id": "cb8c2874",
    "outputId": "2fbe7e45-802f-49c0-994f-819e4296b96f",
    "ExecuteTime": {
     "end_time": "2024-04-05T09:54:06.705429Z",
     "start_time": "2024-04-05T09:54:05.147781Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import import_ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "\n",
    "from Utils.utils import saveArrayInExcelFormat\n",
    "\n",
    "#with open('Data/master_df.pkl','rb') as f: master_df = pickle.load(f)\n",
    "#master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: Results_matrics/ETTm2/N_Linear/ETTm2_fh_48_ph_48.txt -->[0.5897140745554034]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear/ETTm2_fh_96_ph_96.txt -->[0.5990564126645413]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear/ETTm2_fh_192_ph_192.txt -->[0.5072167770898567]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear/ETTm2_fh_336_ph_336.txt -->[0.4203250189504794]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear/ETTm2_fh_720_ph_720.txt -->[0.22624819633815044]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear_MOE/ETTm2_fh_48_ph_48.txt -->[0.5805400665637129]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear_MOE/ETTm2_fh_96_ph_96.txt -->[0.599410062173605]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear_MOE/ETTm2_fh_192_ph_192.txt -->[0.4500920371513523]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear_MOE/ETTm2_fh_336_ph_336.txt -->[0.32639684242165845]\n",
      "\n",
      "Path: Results_matrics/ETTm2/N_Linear_MOE/ETTm2_fh_720_ph_720.txt -->[0.06507305252477014]\n",
      "\n",
      "[[0.5897 0.5991 0.5072 0.4203 0.2262]\n",
      " [0.5805 0.5994 0.4501 0.3264 0.0651]]\n"
     ]
    }
   ],
   "source": [
    "#read file json files\n",
    "def read_file(path):\n",
    "    with open(path, 'r') as file:\n",
    "        # Load JSON data from the file\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "#read metrics from a file\n",
    "def get_dataset_result(path,lst_metrics=['mae','mse'], dic_name='err_results'):\n",
    "    res = read_file(path)\n",
    "    res_err_dic = res[dic_name]\n",
    "    if isinstance(res_err_dic, dict):\n",
    "        json_string = json.dumps(res_err_dic)\n",
    "    else:\n",
    "        json_string = res_err_dic.replace(\"'\", \"\\\"\")\n",
    "    json_data = json.loads(json_string)\n",
    "    #print(json_data)\n",
    "    lst_err = []\n",
    "    for metric in lst_metrics:\n",
    "        lst_err.append(json_data[metric])\n",
    "    return lst_err\n",
    "\n",
    "def get_file_paths(dir,lst_datasets,models,fh,fh_ni,lst_metrics):\n",
    "    files_paths= []\n",
    "    for dataset in lst_datasets:\n",
    "         f_horizon = fh_ni  if dataset == 'national_illness' else fh\n",
    "         for f in f_horizon:\n",
    "            #print(dir+dataset+'/'+models[0]+'/'+dataset+\"_fh_\"+str(f)+\"_ph_\"+str(f)+\".txt\")\n",
    "            files_paths.append(dir+dataset+'/'+models[0]+'/'+dataset+\"_fh_\"+str(f)+\"_ph_\"+str(f)+\".txt\")\n",
    "    return files_paths\n",
    "    #print(files_paths)\n",
    "\n",
    "dir = r'Results_matrics/'\n",
    "#lst_datasets = ['exchange_rate','electricity','traffic','weather','national_illness','ETTh1','ETTh2','ETTm1','ETTm2' ]\n",
    "lst_datasets = ['ETTm2']\n",
    "# models=['N_Linear',\"Simple_Linear\",'DLinearModel','Autoformer','Informer','segRNN','Transformer','VanillaTransformer','GMLP','Mamba','Informer_Transformer_Decoder','BEATS_CELL_Trans_Dec','BEATS_CELL','DC_BEATS','N_Linear_MOE']\n",
    "models=['N_Linear','N_Linear_MOE']\n",
    "fh = [48,96,192,336,720]\n",
    "fh_ni = [24,36,48,60]       #for national_illness dataset\n",
    "#lst_metrics = ['r2','mse','mae']\n",
    "lst_metrics = ['r2']\n",
    "\n",
    "lst_all = []\n",
    "def get_erors(dir, lst_datasets, models,fh,fh_ni,lst_metrics):\n",
    "    lst_tmp = []\n",
    "    for m in models:\n",
    "        lst_paths = get_file_paths(dir, lst_datasets, [m],fh,fh_ni,lst_metrics) #3 autoformer \n",
    "        for p in lst_paths:\n",
    "            print(\"Path: \" + p + ' -->' +  str(get_dataset_result(p,lst_metrics)) + \"\\n\" )\n",
    "            lst_tmp.append(round(get_dataset_result(p,lst_metrics)[0],4))\n",
    "        \n",
    "        lst_all.append(lst_tmp)\n",
    "        lst_tmp= []\n",
    "get_erors(dir, lst_datasets, models,fh,fh_ni,lst_metrics)\n",
    "lst_all = np.asarray(lst_all)\n",
    "print(lst_all)\n",
    "file_p='Results_matrics/'+lst_datasets[0]+'_'+lst_metrics[0]+'_res_table.xlsx' \n",
    "#saveArrayInExcelFormat(lst_all,pd,file_p)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:58:08.104466Z",
     "start_time": "2024-04-05T09:58:08.099551Z"
    }
   },
   "id": "243458a6c6b2038f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8fc1ed1880deb4b6"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dd3e7f4d9321349b50aed1a546ac93300140030fc17f87bed3df5273f9568cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
